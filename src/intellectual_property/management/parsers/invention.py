"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–π —Å –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
"""

import logging
from collections import defaultdict

from django.db import models
from django.utils.text import slugify
from tqdm import tqdm
import pandas as pd

# –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∏–º–ø–æ—Ä—Ç—ã
from intellectual_property.models import IPObject, IPType, Person
from core.models import Organization  # <-- –î–æ–±–∞–≤–ª–µ–Ω —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç
from .base import BaseFIPSParser

logger = logging.getLogger(__name__)


class InventionParser(BaseFIPSParser):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–π —Å –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""

    def get_ip_type(self):
        return IPType.objects.filter(slug='invention').first()

    def get_required_columns(self):
        return ['registration number', 'invention name']

    def _has_data_changed(self, obj, new_data):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ"""
        fields_to_check = [
            ('name', obj.name, new_data['name']),
            ('application_date', obj.application_date, new_data['application_date']),
            ('registration_date', obj.registration_date, new_data['registration_date']),
            ('patent_starting_date', obj.patent_starting_date, new_data['patent_starting_date']),
            ('expiration_date', obj.expiration_date, new_data['expiration_date']),
            ('actual', obj.actual, new_data['actual']),
            ('publication_url', obj.publication_url, new_data['publication_url']),
            ('abstract', obj.abstract, new_data['abstract']),
            ('claims', obj.claims, new_data['claims']),
            ('creation_year', obj.creation_year, new_data['creation_year']),
        ]

        for field_name, old_val, new_val in fields_to_check:
            if old_val != new_val:
                return True
        return False

    def parse_dataframe(self, df, catalogue):
        self.stdout.write(self.style.SUCCESS("  üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–π..."))

        stats = {
            'processed': 0,
            'created': 0,
            'updated': 0,
            'unchanged': 0,
            'skipped': 0,
            'skipped_by_date': 0,
            'errors': 0
        }

        ip_type = self.get_ip_type()
        if not ip_type:
            self.stdout.write(self.style.ERROR("  ‚ùå –¢–∏–ø –†–ò–î 'invention' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î"))
            stats['errors'] += 1
            return stats

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ç–∞–ª–æ–≥–∞
        upload_date = catalogue.upload_date.date() if catalogue.upload_date else None

        # –®–ê–ì 1: –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –Ω–æ–º–µ—Ä–∞
        self.stdout.write("  üì• –ß—Ç–µ–Ω–∏–µ CSV...")
        all_reg_numbers = []
        reg_num_to_row = {}

        with tqdm(total=len(df), desc="     –ü—Ä–æ–≥—Ä–µ—Å—Å", unit=" –∑–∞–ø", leave=False) as pbar:
            for idx, row in df.iterrows():
                reg_num = self.clean_string(row.get('registration number'))
                if reg_num:
                    all_reg_numbers.append(reg_num)
                    reg_num_to_row[reg_num] = row
                pbar.update(1)

        self.stdout.write(f"  üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ CSV: {len(all_reg_numbers)}")

        # –®–ê–ì 2: –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ –ü–ê–ß–ö–ê–ú–ò
        self.stdout.write("  üîç –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î...")
        existing_objects = {}
        batch_size = 500

        with tqdm(total=len(all_reg_numbers), desc="     –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—á–∫–∞–º–∏", unit=" –∑–∞–ø") as pbar:
            for i in range(0, len(all_reg_numbers), batch_size):
                batch_numbers = all_reg_numbers[i:i+batch_size]

                for obj in IPObject.objects.filter(
                    registration_number__in=batch_numbers,
                    ip_type=ip_type
                ).select_related('ip_type'):
                    existing_objects[obj.registration_number] = obj

                pbar.update(len(batch_numbers))

                if (i // batch_size) % 10 == 0:
                    pbar.set_postfix({"–Ω–∞–π–¥–µ–Ω–æ": len(existing_objects)})

        self.stdout.write(f"  üìä –ù–∞–π–¥–µ–Ω–æ –≤ –ë–î: {len(existing_objects)}")

        # –®–ê–ì 3: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.stdout.write("  üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        to_create = []
        to_update = []
        skipped_by_date = []
        unchanged_count = 0
        error_reg_numbers = []

        authors_cache = defaultdict(list)
        holders_cache = defaultdict(list)

        with tqdm(total=len(reg_num_to_row), desc="     –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π", unit=" –∑–∞–ø") as pbar:
            for reg_num, row in reg_num_to_row.items():
                try:
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –¥–∞—Ç–µ
                    if not self.command.force and upload_date and reg_num in existing_objects:
                        existing = existing_objects[reg_num]
                        if existing.updated_at and existing.updated_at.date() >= upload_date:
                            skipped_by_date.append(reg_num)
                            pbar.update(1)
                            continue

                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                    name = self.clean_string(row.get('invention name'))
                    if name:
                        name = self.rid_formatter.format(name)
                    else:
                        name = f"–ò–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–µ ‚Ññ{reg_num}"

                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã
                    application_date = self.parse_date(row.get('application date'))
                    registration_date = self.parse_date(row.get('registration date'))
                    patent_starting_date = self.parse_date(row.get('patent starting date'))
                    expiration_date = self.parse_date(row.get('expiration date'))
                    actual = self.parse_bool(row.get('actual'))
                    publication_url = self.clean_string(row.get('publication URL'))
                    abstract = self.clean_string(row.get('abstract'))
                    claims = self.clean_string(row.get('claims'))

                    creation_year = None
                    if application_date:
                        creation_year = application_date.year
                    elif registration_date:
                        creation_year = registration_date.year

                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    obj_data = {
                        'registration_number': reg_num,
                        'ip_type': ip_type,
                        'name': name,
                        'application_date': application_date,
                        'registration_date': registration_date,
                        'patent_starting_date': patent_starting_date,
                        'expiration_date': expiration_date,
                        'actual': actual,
                        'publication_url': publication_url,
                        'abstract': abstract,
                        'claims': claims,
                        'creation_year': creation_year,
                    }

                    if reg_num in existing_objects:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
                        existing = existing_objects[reg_num]
                        if self._has_data_changed(existing, obj_data):
                            to_update.append(obj_data)
                        else:
                            unchanged_count += 1
                    else:
                        to_create.append(obj_data)

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π
                    authors_str = row.get('authors')
                    if not pd.isna(authors_str) and authors_str:
                        authors_cache[reg_num] = self.parse_authors(authors_str)

                    holders_str = row.get('patent holders')
                    if not pd.isna(holders_str) and holders_str:
                        holders_cache[reg_num] = self.parse_patent_holders(holders_str)

                except Exception as e:
                    error_reg_numbers.append(reg_num)
                    self.stdout.write(self.style.ERROR(f"\n  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏ {reg_num}: {e}"))
                    logger.error(f"Error preparing invention {reg_num}: {e}", exc_info=True)

                pbar.update(1)
                if pbar.n % 1000 == 0:
                    pbar.set_postfix({
                        "–Ω–æ–≤—ã–µ": len(to_create),
                        "–æ–±–Ω–æ–≤": len(to_update),
                        "–±–µ–∑ –∏–∑–º": unchanged_count,
                        "–ø—Ä–æ–ø—É—â": len(skipped_by_date)
                    })

        stats['skipped_by_date'] = len(skipped_by_date)
        stats['skipped'] += len(skipped_by_date)
        stats['errors'] = len(error_reg_numbers)
        stats['unchanged'] = unchanged_count

        self.stdout.write(f"     –ò—Ç–æ–≥–æ: –Ω–æ–≤—ã—Ö={len(to_create)}, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ={len(to_update)}, –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π={unchanged_count}")

        # –®–ê–ì 4: –ü–∞–∫–µ—Ç–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        if to_create and not self.command.dry_run:
            self.stdout.write(f"  üì¶ –°–æ–∑–¥–∞–Ω–∏–µ {len(to_create)} –∑–∞–ø–∏—Å–µ–π...")
            create_objects = [IPObject(**data) for data in to_create]

            batch_size = 1000
            created_count = 0

            with tqdm(total=len(create_objects), desc="     –°–æ–∑–¥–∞–Ω–∏–µ", unit=" –∑–∞–ø") as pbar:
                for i in range(0, len(create_objects), batch_size):
                    batch = create_objects[i:i+batch_size]
                    IPObject.objects.bulk_create(batch, batch_size=batch_size)
                    created_count += len(batch)
                    pbar.update(len(batch))
                    pbar.set_postfix({"—Å–æ–∑–¥–∞–Ω–æ": created_count})

            stats['created'] = created_count

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –Ω–æ–≤—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
            self.stdout.write("     –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞...")

            with tqdm(total=len(to_create), desc="     –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞", unit=" –∑–∞–ø") as pbar:
                for i in range(0, len(to_create), batch_size):
                    batch_data = to_create[i:i+batch_size]
                    batch_nums = [d['registration_number'] for d in batch_data]

                    for obj in IPObject.objects.filter(
                        registration_number__in=batch_nums,
                        ip_type=ip_type
                    ):
                        existing_objects[obj.registration_number] = obj

                    pbar.update(len(batch_data))

        # –®–ê–ì 5: –ü–∞–∫–µ—Ç–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
        if to_update and not self.command.dry_run:
            self.stdout.write(f"  üì¶ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {len(to_update)} –∑–∞–ø–∏—Å–µ–π...")
            updated_count = 0

            with tqdm(total=len(to_update), desc="     –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ", unit=" –∑–∞–ø") as pbar:
                for data in to_update:
                    obj = existing_objects[data['registration_number']]
                    update_fields = []

                    if obj.name != data['name']:
                        obj.name = data['name']
                        update_fields.append('name')

                    if obj.application_date != data['application_date']:
                        obj.application_date = data['application_date']
                        update_fields.append('application_date')

                    if obj.registration_date != data['registration_date']:
                        obj.registration_date = data['registration_date']
                        update_fields.append('registration_date')

                    if obj.patent_starting_date != data['patent_starting_date']:
                        obj.patent_starting_date = data['patent_starting_date']
                        update_fields.append('patent_starting_date')

                    if obj.expiration_date != data['expiration_date']:
                        obj.expiration_date = data['expiration_date']
                        update_fields.append('expiration_date')

                    if obj.actual != data['actual']:
                        obj.actual = data['actual']
                        update_fields.append('actual')

                    if obj.publication_url != data['publication_url']:
                        obj.publication_url = data['publication_url']
                        update_fields.append('publication_url')

                    if obj.abstract != data['abstract']:
                        obj.abstract = data['abstract']
                        update_fields.append('abstract')

                    if obj.claims != data['claims']:
                        obj.claims = data['claims']
                        update_fields.append('claims')

                    if obj.creation_year != data['creation_year']:
                        obj.creation_year = data['creation_year']
                        update_fields.append('creation_year')

                    if update_fields:
                        obj.save(update_fields=update_fields)
                        updated_count += 1

                    pbar.update(1)
                    if pbar.n % 100 == 0:
                        pbar.set_postfix({"–æ–±–Ω–æ–≤–ª–µ–Ω–æ": updated_count})

            stats['updated'] = updated_count
            self.stdout.write(f"     –†–µ–∞–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count} –∏–∑ {len(to_update)}")

        # –®–ê–ì 6: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤
        if authors_cache and not self.command.dry_run:
            self.stdout.write(f"  üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤ ({len(authors_cache)} –∑–∞–ø–∏—Å–µ–π)...")
            self._process_authors_batch_with_progress(existing_objects, authors_cache)

        # –®–ê–ì 7: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ç–µ–Ω—Ç–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π
        if holders_cache and not self.command.dry_run:
            self.stdout.write(f"  üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ç–µ–Ω—Ç–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π ({len(holders_cache)} –∑–∞–ø–∏—Å–µ–π)...")
            self._process_holders_batch_with_progress(existing_objects, holders_cache)

        stats['processed'] = len(df) - stats['skipped'] - stats['errors']

        self.stdout.write(self.style.SUCCESS(f"  ‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω"))
        self.stdout.write(f"     –°–æ–∑–¥–∞–Ω–æ: {stats['created']}, –û–±–Ω–æ–≤–ª–µ–Ω–æ: {stats['updated']}, "
                         f"–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {stats['unchanged']}, "
                         f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –≤—Å–µ–≥–æ: {stats['skipped']} (–∏–∑ –Ω–∏—Ö –ø–æ –¥–∞—Ç–µ: {stats['skipped_by_date']}), "
                         f"–û—à–∏–±–æ–∫: {stats['errors']}")

        return stats

    def _process_authors_batch_with_progress(self, existing_objects, authors_cache):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º –∏ —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –ø–∞—á–∫–∏"""
        self.stdout.write(f"     ‚ö° –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤...")

        # –®–ê–ì 1: –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
        self.stdout.write("        –®–∞–≥ 1/6: –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤...")
        author_to_key = {}
        total_relations = 0

        for reg_num, authors_data in authors_cache.items():
            ip_object = existing_objects.get(reg_num)
            if not ip_object:
                continue

            for author_data in authors_data:
                key = f"{author_data['last_name']}|{author_data['first_name']}|{author_data['middle_name']}"
                if key not in author_to_key:
                    author_to_key[key] = {
                        'data': author_data,
                        'ip_objects': []
                    }
                author_to_key[key]['ip_objects'].append(ip_object)
                total_relations += 1

        all_keys = list(author_to_key.keys())
        self.stdout.write(f"        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {len(all_keys)}, –≤—Å–µ–≥–æ —Å–≤—è–∑–µ–π: {total_relations}")

        # –®–ê–ì 2: –ü–æ–∏—Å–∫ –≤ –ë–î
        self.stdout.write("        –®–∞–≥ 2/6: –ü–æ–∏—Å–∫ –≤ –ë–î...")
        existing_people = {}
        batch_size = 50

        with tqdm(total=len(all_keys), desc="           –ü–æ–∏—Å–∫", unit=" –∫–ª—é—á") as pbar:
            for i in range(0, len(all_keys), batch_size):
                batch_keys = all_keys[i:i+batch_size]

                name_conditions = models.Q()
                for key in batch_keys:
                    last, first, middle = key.split('|')
                    if middle:
                        name_conditions |= models.Q(
                            last_name=last,
                            first_name=first,
                            middle_name=middle
                        )
                    else:
                        name_conditions |= models.Q(
                            last_name=last,
                            first_name=first,
                            middle_name__isnull=True
                        ) | models.Q(
                            last_name=last,
                            first_name=first,
                            middle_name=''
                        )

                for person in Person.objects.filter(name_conditions):
                    key = f"{person.last_name}|{person.first_name}|{person.middle_name or ''}"
                    existing_people[key] = person
                    self.person_cache[key] = person

                pbar.update(len(batch_keys))
                if (i // batch_size) % 10 == 0:
                    pbar.set_postfix({"–Ω–∞–π–¥–µ–Ω–æ": len(existing_people)})

        self.stdout.write(f"        –ù–∞–π–¥–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {len(existing_people)}")

        # –®–ê–ì 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
        self.stdout.write("        –®–∞–≥ 3/6: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤...")
        people_to_create = []
        key_to_new_person = {}

        max_id = Person.objects.aggregate(models.Max('ceo_id'))['ceo_id__max'] or 0
        next_id = max_id + 1
        existing_slugs = set(Person.objects.values_list('slug', flat=True))

        with tqdm(total=len(all_keys), desc="           –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞", unit=" –∫–ª—é—á") as pbar:
            for key, info in author_to_key.items():
                if key not in existing_people:
                    author_data = info['data']

                    name_parts = [author_data['last_name'], author_data['first_name']]
                    if author_data['middle_name']:
                        name_parts.append(author_data['middle_name'])

                    base_slug = slugify(' '.join(name_parts).strip())
                    if not base_slug:
                        base_slug = 'person'

                    unique_slug = base_slug
                    counter = 1
                    while unique_slug in existing_slugs or any(p.slug == unique_slug for p in people_to_create):
                        unique_slug = f"{base_slug}-{counter}"
                        counter += 1

                    person = Person(
                        ceo_id=next_id,
                        ceo=author_data['full_name'],
                        last_name=author_data['last_name'],
                        first_name=author_data['first_name'],
                        middle_name=author_data['middle_name'] or '',
                        slug=unique_slug
                    )
                    people_to_create.append(person)
                    key_to_new_person[key] = person
                    next_id += 1
                    existing_slugs.add(unique_slug)

                pbar.update(1)
                if pbar.n % 10000 == 0:
                    pbar.set_postfix({"–∫ —Å–æ–∑–¥–∞–Ω–∏—é": len(people_to_create)})

        self.stdout.write(f"        –ù–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è: {len(people_to_create)}")

        # –®–ê–ì 4: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
        if people_to_create:
            self.stdout.write(f"        –®–∞–≥ 4/6: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤...")
            batch_size = 500
            created_count = 0

            with tqdm(total=len(people_to_create), desc="           –°–æ–∑–¥–∞–Ω–∏–µ", unit=" —á–µ–ª") as pbar:
                for i in range(0, len(people_to_create), batch_size):
                    batch = people_to_create[i:i+batch_size]
                    Person.objects.bulk_create(batch, batch_size=batch_size)
                    created_count += len(batch)
                    pbar.update(len(batch))
                    pbar.set_postfix({"—Å–æ–∑–¥–∞–Ω–æ": created_count})

            for person in people_to_create:
                key = f"{person.last_name}|{person.first_name}|{person.middle_name}"
                self.person_cache[key] = person

        # –®–ê–ì 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–≤—è–∑–µ–π
        self.stdout.write("        –®–∞–≥ 5/6: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–≤—è–∑–µ–π...")
        unique_pairs = set()
        through_objs = []

        for key, info in author_to_key.items():
            person = existing_people.get(key) or key_to_new_person.get(key)
            if not person:
                continue

            unique_ip_objects = {ip.pk: ip for ip in info['ip_objects']}

            for ip_object in unique_ip_objects.values():
                pair = (ip_object.pk, person.pk)
                if pair not in unique_pairs:
                    unique_pairs.add(pair)
                    through_objs.append(
                        IPObject.authors.through(
                            ipobject_id=ip_object.pk,
                            person_id=person.pk
                        )
                    )

        self.stdout.write(f"        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è: {len(through_objs)}")

        # –®–ê–ì 6: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π
        if through_objs:
            self.stdout.write(f"        –®–∞–≥ 6/6: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π...")

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID IP-–æ–±—ä–µ–∫—Ç–æ–≤
            ip_ids = list(set(obj.ipobject_id for obj in through_objs))
            self.stdout.write(f"           –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Å–≤—è–∑–µ–π –¥–ª—è {len(ip_ids)} IP-–æ–±—ä–µ–∫—Ç–æ–≤...")

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–≤—è–∑–∏ –ü–ê–ß–ö–ê–ú–ò –ø–æ 500 ID
            delete_batch_size = 500
            deleted_total = 0

            for i in range(0, len(ip_ids), delete_batch_size):
                batch_ip_ids = ip_ids[i:i+delete_batch_size]
                deleted, _ = IPObject.authors.through.objects.filter(
                    ipobject_id__in=batch_ip_ids
                ).delete()
                deleted_total += deleted

                if (i // delete_batch_size) % 10 == 0:
                    self.stdout.write(f"              –£–¥–∞–ª–µ–Ω–æ {deleted_total} —Å–≤—è–∑–µ–π...")

            self.stdout.write(f"           –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Å–≤—è–∑–µ–π: {deleted_total}")

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Å–≤—è–∑–∏ –ø–∞—á–∫–∞–º–∏
            create_batch_size = 1000
            created_count = 0

            with tqdm(total=len(through_objs), desc="           –î–æ–±–∞–≤–ª–µ–Ω–∏–µ", unit=" —Å–≤—è–∑—å") as pbar:
                for i in range(0, len(through_objs), create_batch_size):
                    batch = through_objs[i:i+create_batch_size]
                    IPObject.authors.through.objects.bulk_create(batch, batch_size=create_batch_size)
                    created_count += len(batch)
                    pbar.update(len(batch))
                    pbar.set_postfix({"—Å–æ–∑–¥–∞–Ω–æ": created_count})

        self.stdout.write(f"        ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def _process_holders_batch_with_progress(self, existing_objects, holders_cache):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º –∏ —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –ø–∞—á–∫–∏"""
        self.stdout.write(f"     ‚ö° –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π...")

        # –®–ê–ì 1: –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π
        self.stdout.write("        –®–∞–≥ 1/7: –°–±–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π...")
        all_holders = set()
        for holders_list in holders_cache.values():
            all_holders.update(holders_list)

        self.stdout.write(f"        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π: {len(all_holders)}")

        # –®–ê–ì 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        self.stdout.write("        –®–∞–≥ 2/7: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤...")
        person_holders = []
        org_holders = []

        with tqdm(total=len(all_holders), desc="           –ê–Ω–∞–ª–∏–∑", unit=" –æ–±") as pbar:
            for holder in all_holders:
                if self.type_detector.detect_type(holder) == 'person':
                    person_holders.append(holder)
                else:
                    org_holders.append(holder)
                pbar.update(1)

        self.stdout.write(f"        –õ—é–¥–∏: {len(person_holders)}, –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏: {len(org_holders)}")

        # –®–ê–ì 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π (–ß–ê–°–¢–Ø–ú–ò)
        self.stdout.write("        –®–∞–≥ 3/7: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π...")
        org_map = {}

        if org_holders:
            CHUNK_SIZE = 1000
            total_orgs = len(org_holders)

            self.stdout.write(f"        –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_orgs} –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π —á–∞—Å—Ç—è–º–∏ –ø–æ {CHUNK_SIZE}...")

            for chunk_start in range(0, total_orgs, CHUNK_SIZE):
                chunk_end = min(chunk_start + CHUNK_SIZE, total_orgs)
                chunk_holders = org_holders[chunk_start:chunk_end]

                # –ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤ —ç—Ç–æ–π —á–∞—Å—Ç–∏
                existing_orgs = {}
                for org in Organization.objects.filter(name__in=chunk_holders):
                    existing_orgs[org.name] = org
                    self.organization_cache[org.name] = org

                # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –≤ —ç—Ç–æ–π —á–∞—Å—Ç–∏
                orgs_to_create = []
                for holder in chunk_holders:
                    if holder not in existing_orgs and holder not in self.organization_cache:
                        max_id = Organization.objects.aggregate(models.Max('organization_id'))['organization_id__max'] or 0
                        new_id = max_id + len(orgs_to_create) + 1

                        base_slug = slugify(holder[:50])
                        if not base_slug:
                            base_slug = 'organization'

                        unique_slug = base_slug
                        counter = 1
                        while Organization.objects.filter(slug=unique_slug).exists() or any(o.slug == unique_slug for o in orgs_to_create):
                            unique_slug = f"{base_slug}-{counter}"
                            counter += 1

                        org = Organization(
                            organization_id=new_id,
                            name=holder,
                            full_name=holder,
                            short_name=holder[:500] if len(holder) > 500 else holder,
                            slug=unique_slug,
                            register_opk=False,
                            strategic=False,
                        )
                        orgs_to_create.append(org)
                        self.organization_cache[holder] = org

                # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ —Å–æ–∑–¥–∞–µ–º –≤ –ë–î
                if orgs_to_create:
                    batch_size = 500
                    for i in range(0, len(orgs_to_create), batch_size):
                        batch = orgs_to_create[i:i+batch_size]
                        Organization.objects.bulk_create(batch, batch_size=batch_size)

                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
                del existing_orgs
                del orgs_to_create

                progress = (chunk_end / total_orgs) * 100
                self.stdout.write(f"           –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%")

            # –§–∏–Ω–∞–ª—å–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥
            for holder in org_holders:
                org_map[holder] = self.organization_cache.get(holder)

        # –®–ê–ì 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª—é–¥–µ–π (–ß–ê–°–¢–Ø–ú–ò)
        self.stdout.write("        –®–∞–≥ 4/7: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª—é–¥–µ–π...")
        person_map = {}

        if person_holders:
            CHUNK_SIZE = 500
            total_people = len(person_holders)

            self.stdout.write(f"        –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_people} –ª—é–¥–µ–π —á–∞—Å—Ç—è–º–∏ –ø–æ {CHUNK_SIZE}...")

            for chunk_start in range(0, total_people, CHUNK_SIZE):
                chunk_end = min(chunk_start + CHUNK_SIZE, total_people)
                chunk_holders = person_holders[chunk_start:chunk_end]

                # –ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö
                existing_people = {}
                for holder in chunk_holders:
                    parts = holder.split()
                    if len(parts) >= 2:
                        last_name = parts[0]
                        first_name = parts[1]
                        middle_name = parts[2] if len(parts) > 2 else ''

                        persons = Person.objects.filter(
                            last_name=last_name,
                            first_name=first_name
                        )
                        if middle_name:
                            persons = persons.filter(middle_name=middle_name)

                        person = persons.first()
                        if person:
                            existing_people[holder] = person
                            self.person_cache[holder] = person

                # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö
                people_to_create = []
                for holder in chunk_holders:
                    if holder not in existing_people and holder not in self.person_cache:
                        parts = holder.split()
                        if len(parts) >= 2:
                            last_name = parts[0]
                            first_name = parts[1]
                            middle_name = parts[2] if len(parts) > 2 else ''

                            name_parts = [last_name, first_name]
                            if middle_name:
                                name_parts.append(middle_name)

                            base_slug = slugify(' '.join(name_parts))
                            if not base_slug:
                                base_slug = 'person'

                            unique_slug = base_slug
                            counter = 1
                            while Person.objects.filter(slug=unique_slug).exists() or any(p.slug == unique_slug for p in people_to_create):
                                unique_slug = f"{base_slug}-{counter}"
                                counter += 1

                            max_id = Person.objects.aggregate(models.Max('ceo_id'))['ceo_id__max'] or 0
                            new_id = max_id + len(people_to_create) + 1

                            person = Person(
                                ceo_id=new_id,
                                ceo=holder,
                                last_name=last_name,
                                first_name=first_name,
                                middle_name=middle_name or '',
                                slug=unique_slug
                            )
                            people_to_create.append(person)
                            self.person_cache[holder] = person

                # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ —Å–æ–∑–¥–∞–µ–º –≤ –ë–î
                if people_to_create:
                    batch_size = 500
                    for i in range(0, len(people_to_create), batch_size):
                        batch = people_to_create[i:i+batch_size]
                        Person.objects.bulk_create(batch, batch_size=batch_size)

                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
                del existing_people
                del people_to_create

                progress = (chunk_end / total_people) * 100
                self.stdout.write(f"           –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}%")

            # –§–∏–Ω–∞–ª—å–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥
            for holder in person_holders:
                person_map[holder] = self.person_cache.get(holder)

        # –®–ê–ì 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–≤—è–∑–µ–π
        self.stdout.write("        –®–∞–≥ 5/7: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–≤—è–∑–µ–π...")

        org_relations = set()
        person_relations = set()

        with tqdm(total=sum(len(h) for h in holders_cache.values()), desc="           –°–±–æ—Ä —Å–≤—è–∑–µ–π", unit=" —Å–≤") as pbar:
            for reg_num, holders_list in holders_cache.items():
                ip_object = existing_objects.get(reg_num)
                if not ip_object:
                    continue

                for holder in holders_list:
                    if holder in org_map and org_map[holder]:
                        org_relations.add((ip_object.pk, org_map[holder].pk))
                    elif holder in person_map and person_map[holder]:
                        person_relations.add((ip_object.pk, person_map[holder].pk))
                    pbar.update(1)

        self.stdout.write(f"        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏: {len(org_relations)}")
        self.stdout.write(f"        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π —Å –ª—é–¥—å–º–∏: {len(person_relations)}")

        # –®–ê–ì 6: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏
        if org_relations:
            self.stdout.write("        –®–∞–≥ 6/7: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏...")

            ip_ids = list(set(ip_id for ip_id, _ in org_relations))

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–≤—è–∑–∏ –ü–ê–ß–ö–ê–ú–ò
            delete_batch_size = 500
            deleted_total = 0
            for i in range(0, len(ip_ids), delete_batch_size):
                batch_ip_ids = ip_ids[i:i+delete_batch_size]
                deleted, _ = IPObject.owner_organizations.through.objects.filter(
                    ipobject_id__in=batch_ip_ids
                ).delete()
                deleted_total += deleted
                if (i // delete_batch_size) % 10 == 0:
                    self.stdout.write(f"              –£–¥–∞–ª–µ–Ω–æ {deleted_total} —Å–≤—è–∑–µ–π —Å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º–∏...")

            self.stdout.write(f"           –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Å–≤—è–∑–µ–π: {deleted_total}")

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Å–≤—è–∑–∏ –ø–∞—á–∫–∞–º–∏
            through_objs = [
                IPObject.owner_organizations.through(
                    ipobject_id=ip_id,
                    organization_id=org_id
                )
                for ip_id, org_id in org_relations
            ]

            create_batch_size = 1000
            created_count = 0
            with tqdm(total=len(through_objs), desc="           –î–æ–±–∞–≤–ª–µ–Ω–∏–µ", unit=" —Å–≤") as pbar:
                for i in range(0, len(through_objs), create_batch_size):
                    batch = through_objs[i:i+create_batch_size]
                    IPObject.owner_organizations.through.objects.bulk_create(batch, batch_size=create_batch_size)
                    created_count += len(batch)
                    pbar.update(len(batch))

        # –®–ê–ì 7: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –ª—é–¥—å–º–∏
        if person_relations:
            self.stdout.write("        –®–∞–≥ 7/7: –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π —Å –ª—é–¥—å–º–∏...")

            ip_ids = list(set(ip_id for ip_id, _ in person_relations))

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–≤—è–∑–∏ –ü–ê–ß–ö–ê–ú–ò
            delete_batch_size = 500
            deleted_total = 0
            for i in range(0, len(ip_ids), delete_batch_size):
                batch_ip_ids = ip_ids[i:i+delete_batch_size]
                deleted, _ = IPObject.owner_persons.through.objects.filter(
                    ipobject_id__in=batch_ip_ids
                ).delete()
                deleted_total += deleted
                if (i // delete_batch_size) % 10 == 0:
                    self.stdout.write(f"              –£–¥–∞–ª–µ–Ω–æ {deleted_total} —Å–≤—è–∑–µ–π —Å –ª—é–¥—å–º–∏...")

            self.stdout.write(f"           –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Å–≤—è–∑–µ–π: {deleted_total}")

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Å–≤—è–∑–∏ –ø–∞—á–∫–∞–º–∏
            through_objs = [
                IPObject.owner_persons.through(
                    ipobject_id=ip_id,
                    person_id=person_id
                )
                for ip_id, person_id in person_relations
            ]

            create_batch_size = 1000
            created_count = 0
            with tqdm(total=len(through_objs), desc="           –î–æ–±–∞–≤–ª–µ–Ω–∏–µ", unit=" —Å–≤") as pbar:
                for i in range(0, len(through_objs), create_batch_size):
                    batch = through_objs[i:i+create_batch_size]
                    IPObject.owner_persons.through.objects.bulk_create(batch, batch_size=create_batch_size)
                    created_count += len(batch)
                    pbar.update(len(batch))

        self.stdout.write(f"        ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∞–≤–æ–æ–±–ª–∞–¥–∞—Ç–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
